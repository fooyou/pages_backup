<!DOCTYPE html>
<!-- <html class="fuelux" lang="en"> -->
<html class="fuelux" lang="en">
    <head>
        <meta charset="utf-8">
        <title>Scrapy 学习笔记（一）</title>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="">
        <meta name="author" content="">
        <script src="/js/jquery.min.js" type="text/javascript"></script>
        <link href="/css/fuelux.css" rel="stylesheet" />
        <link href="/css/fuelux-responsive.css" rel="stylesheet" />
        <script src="/js/loader.min.js" type="text/javascript"></script>
        <link href="/css/style_midnight.css" rel="stylesheet">
        <link rel="shortcut icon" href="/favicon.ico">
    </head>
    <body data-spy="scroll" data-target=".subnav" data-offset="50">
        <div class="navbar navbar-fixed-top">
    <div class="navbar-inner">
        <div class="container">
            <!--
            <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </a>
            -->
            <div class="row">
                <div class="span8 columns">
                    <a class="brand" href="http://fooyou.github.io">书亚博园</a>
                </div>
                <div class="span3 columns">
                    <a class="brand" href="http://fooyou.github.io/atom.xml">RSS</a>
                </div>
            </div>
            <!--
            <div class="nav-collapse">
                <ul class="nav">
                    <li class="">
                        <a href="http://fooyou.github.io"><i class="icon-home"></i> 主页</a>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="icon-comment"></i> 社交 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            <li class=""><a href="http://www.linkedin.com/pub/joshua-liu/8a/a75/3a2" rel="tooltip" title="到领英找我" target="_blank">LinkedIn</a></li>
                            <li class="divider"></li>
                            <li class=""><a href="http://fooyou.github.io/atom.xml" rel="tooltip" title="RSS订阅" target="_blank">RSS</a></li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="icon-list"></i> 项目 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            <li class=""><a href="https://github.com/fooyou/notes" rel="tooltip" title="学习笔记" target="_blank">笔记</a></li>
                        </ul>
                    </li>
                </ul>
            </div>
            -->
        </div>
    </div>
</div>
        <div class="container">
            <div class="marketing">
                <link rel="stylesheet" href="/css/pygments/trac.css">

<!-- 添加公式支持 -->


<div class="content">
    <script type="text/javascript">
	// //* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
	// var disqus_shortname = 'meshinestar'; // required: replace example with your forum shortname
	// var disqus_identifier = '/blog/scrapy-simple-learning-01';
	// var disqus_url = 'http://fooyou.github.io/blog/scrapy-simple-learning-01';
	// //* * * DON'T EDIT BELOW THIS LINE * * */
	// (function () {
	// 	var s = document.createElement('script'); s.async = true;
	// 	s.type = 'text/javascript';
	// 	s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
	// 	(document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
	// }());
</script>

<div class="row">
    <div class="span12 column">
        <p><h1>Scrapy 学习笔记（一）</h1></p>
    </div>
</div>
<div class="row">
    <div class="span12 column">
        <h5><strong>2015-04-24 <small>. Document . <a href="http://fooyou.github.io/blog/scrapy-simple-learning-01#disqus_thread" data-disqus-identifier="/blog/scrapy-simple-learning-01">评论</a></small></strong>
        <br/><small>标签:  <a href="/tags/python" title="按标签 &quot;python&quot;浏览"><u>python</u></a>     <a href="/tags/scrapy" title="按标签 &quot;scrapy&quot;浏览"><u>scrapy</u></a>    </small><br/><br/>
    </div>
</div>
<div class="row">
    <div class="span6 column">
    </div>
    <div class="span3 column">
        <p class="pull-right"> <a href="/blog/virtualenv-you-want-it" title="上一篇: virtualenv解决Python开发环境问题的神器"><i class="icon-chevron-left"></i></a> 	    	<a href="/blog/mind-through" title="下一篇: 油盐酱醋谈生活"><i class="icon-chevron-right"></i></a> 	 </p>
    </div>
</div>
    <p>本文以dmoz.org网站为例，介绍简单的scrapy爬虫的创建。</p>

<p><br>
<br></p>

<h2 id="创建项目">创建项目</h2>

<p>Scrapy必须要创建项目先，然后在项目目录下方能工作。如下命令创建：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">$ scrapy startproject tutorial
</code></pre></div>
<p>之后，你能看到新建的scrapy工程目录：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">└── tutorial
    ├── scrapy.cfg            ：项目的配置文件
    └── tutorial          ：该项目的Python模块。之后将在此加入代码。
        ├── __init__.py
        ├── items.py      ：项目中的item文件。
        ├── pipelines.py  ：项目中的piplines文件。
        ├── settings.py       ：项目的设置文件。
        └── spiders           ：放置spider代码的目录
            └── __init__.py
</code></pre></div>
<p><br>
<br></p>

<h2 id="定义item">定义Item</h2>

<p><em>Item</em> 是保存爬取到的数据的容器；其使用方法和python字典类似， 并且提供了额外保护机制来避免拼写错误导致的未定义字段错误。</p>

<p>首先根据需要从dmoz.org获取到的数据对item进行建模。 我们需要从dmoz中获取名字，url，以及网站的描述。 对此，在item中定义相应的字段。编辑 tutorial 目录中的 items.py 文件:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">DmozItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">link</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">desc</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</code></pre></div>
<p><br>
<br></p>

<h2 id="编写第一个爬虫（spider）">编写第一个爬虫（Spider）</h2>

<p>Spider是用户编写用于从单个网站(或者一些网站)爬取数据的类。</p>

<p>其包含了一个用于下载的初始URL，如何跟进网页中的链接以及如何分析页面中的内容， 提取生成 <code>item</code> 的方法。</p>

<p>为了创建一个Spider，您必须继承 <code>scrapy.Spider</code> 类， 且定义以下三个属性:</p>

<ul>
<li><code>name</code>：用于区别Spider。 该名字必须是唯一的，您不可以为不同的Spider设定相同的名字。</li>
<li><code>start_urls</code>：包含了Spider在启动时进行爬取的url列表。 因此，第一个被获取到的页面将是其中之一。 后续的URL则从初始的URL获取到的数据中提取。</li>
<li><code>parse()</code>：是spider的一个方法。 被调用时，每个初始URL完成下载后生成的 <code>Response</code>对象将会作为唯一的参数传递给该函数。 该方法负责解析返回的数据(response data)，提取数据(生成item)以及生成需要进一步处理的URL的 <code>Request</code> 对象。</li>
</ul>

<p>以下为我们的第一个Spider代码，保存在 <code>tutorial/spiders</code> 目录下的 <code>dmoz_spider.py</code> 文件中:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">DmozSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&quot;dmoz&quot;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;dmoz.org&quot;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">&quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&quot;</span><span class="p">,</span>
        <span class="s">&quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&quot;</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
</code></pre></div>
<p><br>
<br></p>

<h2 id="爬取">爬取</h2>

<p>进入项目的根目录，执行下列命令启动spider:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">scrapy crawl dmoz
</code></pre></div>
<p><code>crawl dmoz</code> 启动用于爬取 <code>dmoz.org</code> 的spider，您将得到类似的输出:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">2015-04-24 15:45:12+0800 [scrapy] INFO: Scrapy 0.24.6 started (bot: tutorial)
2015-04-24 15:45:12+0800 [scrapy] INFO: Optional features available: ssl, http11, django
2015-04-24 15:45:12+0800 [scrapy] INFO: Overridden settings: {&#39;NEWSPIDER_MODULE&#39;: &#39;tutorial.spiders&#39;, &#39;SPIDER_MODULES&#39;: [&#39;tutorial.spiders&#39;], &#39;BOT_NAME&#39;: &#39;tutorial&#39;}
2015-04-24 15:45:12+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2015-04-24 15:45:12+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, HttpProxyMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-04-24 15:45:12+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-04-24 15:45:12+0800 [scrapy] INFO: Enabled item pipelines: 
2015-04-24 15:45:12+0800 [dmoz] INFO: Spider opened
2015-04-24 15:45:12+0800 [dmoz] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-04-24 15:45:12+0800 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-04-24 15:45:12+0800 [scrapy] DEBUG: Web service listening on 127.0.0.1:6080
2015-04-24 15:45:13+0800 [dmoz] DEBUG: Crawled (200) &lt;GET http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&gt; (referer: None)
2015-04-24 15:45:14+0800 [dmoz] DEBUG: Crawled (200) &lt;GET http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&gt; (referer: None)
2015-04-24 15:45:14+0800 [dmoz] INFO: Closing spider (finished)
2015-04-24 15:45:14+0800 [dmoz] INFO: Dumping Scrapy stats:
    {&#39;downloader/request_bytes&#39;: 516,
     &#39;downloader/request_count&#39;: 2,
     &#39;downloader/request_method_count/GET&#39;: 2,
     &#39;downloader/response_bytes&#39;: 16670,
     &#39;downloader/response_count&#39;: 2,
     &#39;downloader/response_status_count/200&#39;: 2,
     &#39;finish_reason&#39;: &#39;finished&#39;,
     &#39;finish_time&#39;: datetime.datetime(2015, 4, 24, 7, 45, 14, 17440),
     &#39;log_count/DEBUG&#39;: 4,
     &#39;log_count/INFO&#39;: 7,
     &#39;response_received_count&#39;: 2,
     &#39;scheduler/dequeued&#39;: 2,
     &#39;scheduler/dequeued/memory&#39;: 2,
     &#39;scheduler/enqueued&#39;: 2,
     &#39;scheduler/enqueued/memory&#39;: 2,
     &#39;start_time&#39;: datetime.datetime(2015, 4, 24, 7, 45, 12, 133706)}
2015-04-24 15:45:14+0800 [dmoz] INFO: Spider closed (finished)
</code></pre></div>
<p>查看包含 [dmoz] 的输出，可以看到输出的log中包含定义在 start_urls 的初始URL，并且与spider中是一一对应的。在log中可以看到其没有指向其他页面( (referer:None) )。</p>

<p>除此之外，更有趣的事情发生了。就像我们 parse 方法指定的那样，有两个包含url所对应的内容的文件被创建了: Book , Resources 。</p>

<p>** 刚才发生了什么 **</p>

<p>Scrapy为Spider的 <code>start_urls</code> 属性中的每个URL创建了 <code>scrapy.Request</code> 对象，并将 <code>parse</code> 方法作为回调函数(callback)赋值给了Request。</p>

<p>Request对象经过调度，执行生成 <code>scrapy.http.Response</code> 对象并送回给spider parse() 方法。</p>

<p><br>
<br></p>

<h2 id="提取item">提取Item</h2>

<p><strong>Selectors选择器简介</strong></p>

<p>从网页中提取数据有很多方法。Scrapy使用了一种基于 <code>XPath</code> 和 <code>CSS</code> 表达式机制: <code>Scrapy Selectors</code> 。 关于selector和其他提取机制的信息请参考 Selector文档 。</p>

<p>这里给出XPath表达式的例子及对应的含义:</p>

<ul>
<li><code>/html/head/title:</code> 选择HTML文档中 <code>&lt;head&gt;</code> 标签内的 <code>&lt;title&gt;</code> 元素</li>
<li><code>/html/head/title/text():</code> 选择上面提到的 <code>&lt;title&gt;</code> 元素的文字</li>
<li><code>//td:</code> 选择所有的 <code>&lt;td&gt;</code> 元素</li>
<li><code>//div[@class=&quot;mine&quot;]:</code> 选择所有具有 <code>class=&quot;mine&quot;</code> 属性的 <code>div</code> 元素</li>
</ul>

<p>上边仅仅是几个简单的XPath例子，XPath实际上要比这远远强大的多。 如果您想了解的更多，我们推荐 这篇<a href="http://www.w3schools.com/XPath/default.asp">XPath教程</a> 。</p>

<p>为了配合XPath，Scrapy除了提供了 Selector 之外，还提供了方法来避免每次从response中提取数据时生成selector的麻烦。</p>

<p>Selector有四个基本的方法(点击相应的方法可以看到详细的API文档):</p>

<ul>
<li><code>xpath()</code>: 传入xpath表达式，返回该表达式所对应的所有节点的selector list列表 。</li>
<li><code>css()</code>: 传入CSS表达式，返回该表达式所对应的所有节点的selector list列表.</li>
<li><code>extract()</code>: 序列化该节点为unicode字符串并返回list。</li>
<li><code>re()</code>: 根据传入的正则表达式对数据进行提取，返回unicode字符串list列表。</li>
</ul>

<p>在查看了网页的源码后，您会发现网站的信息是被包含在 第二个 <ul> 元素中。</p>

<p>我们可以通过这段代码选择该页面中网站列表里所有 <li> 元素:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">sel.xpath(&#39;//ul/li&#39;)
</code></pre></div>
<p>网站的描述:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">sel.xpath(&#39;//ul/li/text()&#39;).extract()
</code></pre></div>
<p>网站的标题:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">sel.xpath(&#39;//ul/li/a/text()&#39;).extract()
</code></pre></div>
<p>以及网站的链接:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">sel.xpath(&#39;//ul/li/a/@href&#39;).extract()
</code></pre></div>
<p>之前提到过，每个 .xpath() 调用返回selector组成的list，因此我们可以拼接更多的 .xpath() 来进一步获取某个节点。我们将在下边使用这样的特性:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">sel</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//ul/li&#39;</span><span class="p">):</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;a/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
    <span class="n">link</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;a/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
    <span class="n">desc</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
    <span class="k">print</span> <span class="n">title</span><span class="p">,</span> <span class="n">link</span><span class="p">,</span> <span class="n">desc</span>
</code></pre></div>
<p>在我们的spider中加入这段代码:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">import scrapy

class DmozSpider(scrapy.Spider):
    name = &quot;dmoz&quot;
    allowed_domains = [&quot;dmoz.org&quot;]
    start_urls = [
        &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&quot;,
        &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&quot;
    ]

    def parse(self, response):
        for sel in response.xpath(&#39;//ul/li&#39;):
            title = sel.xpath(&#39;a/text()&#39;).extract()
            link = sel.xpath(&#39;a/@href&#39;).extract()
            desc = sel.xpath(&#39;text()&#39;).extract()
            print title, link, desc
</code></pre></div>
<p>现在尝试再次爬取dmoz.org，您将看到爬取到的网站信息被成功输出:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">scrapy crawl dmoz
</code></pre></div>
<h2 id="使用item">使用Item</h2>

</div>

<div class="row">
    <div class="span6 column">
    </div>
    <div class="span3 column">
        <br>
        <p class="pull-right"> <a href="/blog/virtualenv-you-want-it" title="上一篇: virtualenv解决Python开发环境问题的神器"><i class="icon-chevron-left"></i></a>          <a href="/blog/mind-through" title="下一篇: 油盐酱醋谈生活"><i class="icon-chevron-right"></i></a>    </p>
    </div>
</div>


<div class="row">
    <div class="span12 columns">
        <h2>评论</h2>
        <p>欢迎回复，请保证一不跑题二要干净</p>
        <!-- 使用的是外国的disqus评论服务，国内有一个叫多说的评论服务也不错（http://duoshuo.com/） -->
        <div id="disqus_thread"></div>
        <script type="text/javascript">
            //* * * CONFIGURATION VARIABLES * * */
            var disqus_shortname = 'meshinestar';
            
            //* * * DON'T EDIT BELOW THIS LINE * * */
            (function() {
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
    </div>
</div>


            </div>
        </div>
        <footer class="footer">
  <div class="container">
	<p class="pull-right"> <a href="/blog/virtualenv-you-want-it" title="Previous Post: virtualenv解决Python开发环境问题的神器">&laquo; 上一篇</a> 	  |  <a href="#">回到顶</a>  |   	<a href="/blog/mind-through" title="Next Post: 油盐酱醋谈生活">下一篇 &raquo; </a> 	 </p>        
	<p>页面最后生成于 2015-09-09</p>
	<p>如果需要, <a href="mailto:liuchaozhenyu@gmail.com" title="邮件联系我"  target="_blank" >邮件联系我</a>.</p>

    <!-- Twitter No need to open this code -->
<!--     <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script> -->

    <!-- Google + -->
<!--     <script type="text/javascript">
      (function() {
        var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
        po.src = 'https://apis.google.com/js/plusone.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
      })();
    </script> -->

  </div>
</footer>

        

        <script type="text/javascript">
            // //* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            // var disqus_shortname = 'meshinestar'; // required: replace example with your forum shortname
            // //* * * DON'T EDIT BELOW THIS LINE * * */
            // (function () {
            //     var s = document.createElement('script'); s.async = true;
            //     s.type = 'text/javascript';
            //     s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
            //     (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
            // }());
        </script>

        <!-- Google Analytics -->
        <!--    <script type="text/javascript">
        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-29830549-1']);
        _gaq.push(['_trackPageview']);
        (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
        </script>    -->
    </body>
</html>